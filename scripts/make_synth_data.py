# scripts/make_synth_data.py
# Generates realistic synthetic data for EduRecSys:
#   - data/processed/train.csv (user_id,item_id,timestamp,event_type,value)
#   - data/processed/item_catalog.csv (item_id,title,description,topic,difficulty)

import os
from datetime import datetime, timedelta
import numpy as np
import pandas as pd

# -------- config --------
N_USERS, N_ITEMS, N_TOPICS = 1200, 320, 8
TOPICS = [
    "Data Science","Web Dev","Mobile Dev","Cloud & DevOps",
    "AI/ML","Cybersecurity","Productivity","Business & Finance"
]
DIFFS = ["Beginner","Intermediate","Advanced"]
DAYS = 120
AVG_INTERACTIONS_PER_USER = 25
P_SESSION = 0.6
SESSION_LEN_MEAN = 3.0
NOISE_RATE = 0.15
# (event_type, value, relative weight)
EVENTS = [
    ("view", 1.0, 0.75),
    ("click", 1.0, 0.50),
    ("wishlist", 1.5, 0.25),
    ("enroll", 2.0, 0.15),
    ("complete", 3.0, 0.20),
]
rng = np.random.default_rng(42)

# -------- catalog --------
items = pd.DataFrame({"item_id": np.arange(1, N_ITEMS+1, dtype=int)})
items["topic"] = rng.choice(TOPICS[:N_TOPICS], size=N_ITEMS)
items["difficulty"] = rng.choice(DIFFS, size=N_ITEMS, p=[0.5, 0.35, 0.15])
items["title"] = [
    f"{row.topic} • {row.difficulty} #{iid:03d}"
    for iid, row in items.set_index("item_id").iterrows()
]
items["description"] = [
    f"Autogenerated {row.topic} course. Level: {row.difficulty}."
    for _, row in items.iterrows()
]

# -------- user profiles --------
users = np.arange(1, N_USERS+1, dtype=int)
profiles = []
for u in users:
    p = rng.choice(TOPICS[:N_TOPICS])
    s = rng.choice([t for t in TOPICS[:N_TOPICS] if t != p])
    d = rng.choice(DIFFS, p=[0.55, 0.35, 0.10])
    profiles.append((u, p, s, d))
prof = pd.DataFrame(profiles, columns=["user_id","topic_primary","topic_secondary","difficulty_pref"])

topic_to_items = {t: items.loc[items.topic == t, "item_id"].tolist() for t in TOPICS[:N_TOPICS]}
diff_to_items  = {d: items.loc[items.difficulty == d, "item_id"].tolist() for d in DIFFS}

# -------- interactions --------
start = datetime.utcnow() - timedelta(days=DAYS)
def ts():
    return int((start + timedelta(seconds=int(rng.integers(0, DAYS*24*3600)))).timestamp())

rows = []
weights = np.array([e[2] for e in EVENTS], dtype=float); weights /= weights.sum()

for _, r in prof.iterrows():
    u = int(r.user_id)
    t1, t2, d = r.topic_primary, r.topic_secondary, r.difficulty_pref
    n = max(5, int(rng.normal(AVG_INTERACTIONS_PER_USER, AVG_INTERACTIONS_PER_USER*0.4)))
    i = 0
    while i < n:
        # multi-item session (creates co-occurrence)
        if rng.random() < P_SESSION:
            L = max(2, int(rng.normal(SESSION_LEN_MEAN, 1.0)))
            session = []
            for _ in range(L):
                topic = (
                    rng.choice([t1]*5 + [t2]*3 + TOPICS[:N_TOPICS])
                    if rng.random() > NOISE_RATE else
                    rng.choice(TOPICS[:N_TOPICS])
                )
                cand = topic_to_items[topic]
                if rng.random() < 0.6:
                    c2 = list(set(cand).intersection(diff_to_items[d])) or cand
                    cand = c2
                session.append(int(rng.choice(cand)))
            session = list(dict.fromkeys(session))  # unique, keep order
            t0 = ts()
            for it in session:
                et, val, _ = rng.choice(EVENTS, p=weights)
                rows.append((u, it, t0 + int(rng.integers(0, 600)), et, float(val)))
            i += len(session)
        else:
            topic = t1 if rng.random() < 0.7 else (t2 if rng.random() < 0.6 else rng.choice(TOPICS[:N_TOPICS]))
            it = int(rng.choice(topic_to_items[topic]))
            if rng.random() < 0.6:
                pool = list(set([it]).intersection(diff_to_items[d])) or [it]
                it = int(rng.choice(pool))
            et, val, _ = rng.choice(EVENTS, p=weights)
            rows.append((u, it, ts(), et, float(val)))
            i += 1

log = pd.DataFrame(rows, columns=["user_id","item_id","timestamp","event_type","value"])
log.sort_values(["user_id","timestamp"], inplace=True, kind="mergesort")

os.makedirs("data/processed", exist_ok=True)
log.to_csv("data/processed/train.csv", index=False)
items[["item_id","title","description","topic","difficulty"]].to_csv("data/processed/item_catalog.csv", index=False)

# quick suggestions for demo
top_users = (
    log.groupby("user_id")["item_id"].count().sort_values(ascending=False).head(10).index.tolist()
)
top_items = log["item_id"].value_counts().head(10).index.tolist()

print("✅ Wrote data/processed/train.csv and data/processed/item_catalog.csv")
print("users:", log.user_id.nunique(), "items:", log.item_id.nunique(), "rows:", len(log))
print("Try these user_ids for personalization:", top_users[:5])
print("Popular items (often have neighbors):", top_items[:5])
